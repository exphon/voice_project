# voice_app/whisper_utils.py

import whisper
import time
import os
import gc
import torch
import json

# whisperxëŠ” ì„ íƒì  ì˜ì¡´ì„±
try:
    import whisperx
    WHISPERX_AVAILABLE = True
    print("[WhisperX] WhisperX module available")
except ImportError:
    WHISPERX_AVAILABLE = False
    print("[WhisperX] WhisperX module not available, using basic Whisper only")

# ğŸ’¡ ì „ì—­ì—ì„œ í•œ ë²ˆë§Œ ëª¨ë¸ ë¡œë”© (ì„±ëŠ¥ ìµœì í™”)
try:
    print("[Whisper] Loading model...")
    model = whisper.load_model("base")  # GPU ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ base ëª¨ë¸ ì‚¬ìš©
    print("[Whisper] Model loaded successfully.")
except Exception as e:
    model = None
    print(f"[Whisper Error] Failed to load model: {e}")

# WhisperX ëª¨ë¸ ì „ì—­ ë³€ìˆ˜ (lazy loading) - whisperx ì‚¬ìš© ì‹œì—ë§Œ í•„ìš”
whisperx_model = None
whisperx_model_a = None
whisperx_metadata = None
diarize_model = None

def get_whisperx_model():
    """WhisperX ëª¨ë¸ì„ lazy loadingìœ¼ë¡œ ê°€ì ¸ì˜´"""
    global whisperx_model, whisperx_model_a, whisperx_metadata, diarize_model
    
    if not WHISPERX_AVAILABLE:
        print("[WhisperX Error] WhisperX is not installed")
        return None, None, None
    
    if whisperx_model is None:
        try:
            device = "cuda" if torch.cuda.is_available() else "cpu"
            batch_size = 8 if device == "cuda" else 4  # batch size ì¤„ì„
            compute_type = "float16" if device == "cuda" else "int8"
            
            print(f"[WhisperX] Loading model on {device}...")
            # GPU ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ base ë˜ëŠ” small ëª¨ë¸ ì‚¬ìš©
            whisperx_model = whisperx.load_model("base", device, compute_type=compute_type)
            
            # alignment model (í•œêµ­ì–´ ì§€ì›)
            whisperx_model_a, whisperx_metadata = whisperx.load_align_model(language_code="ko", device=device)
            
            print("[WhisperX] Models loaded successfully.")
        except Exception as e:
            print(f"[WhisperX Error] Failed to load models: {e}")
            return None, None, None
    
    return whisperx_model, whisperx_model_a, whisperx_metadata


def transcribe_audio(audio_path):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ Whisperë¡œ ì „ì‚¬í•˜ê³  ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ None ë°˜í™˜.

    Args:
        audio_path (str): íŒŒì¼ ê²½ë¡œ

    Returns:
        str or None: ì „ì‚¬ ê²°ê³¼ ë˜ëŠ” None
    """
    if not model:
        print("[Whisper Error] Model not loaded.")
        return None

    if not os.path.exists(audio_path):
        print(f"[Whisper Error] File does not exist: {audio_path}")
        return None

    try:
        start = time.time()
        result = model.transcribe(audio_path, fp16=False, temperature=0.0, language="ko")
        elapsed = time.time() - start
        print(f"[Whisper] Transcription completed in {elapsed:.2f} seconds.")
        return result['text']
    except Exception as e:
        print(f"[Whisper Error] Failed to transcribe {audio_path}: {e}")
        return None


def transcribe_and_align_whisperx(audio_path):
    """
    WhisperXë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì‚¬ ë° forced alignment ìˆ˜í–‰
    
    Args:
        audio_path (str): ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        dict: {
            'transcription': str,
            'segments': list,
            'word_segments': list,
            'success': bool,
            'error': str or None
        }
    """
    if not WHISPERX_AVAILABLE:
        return {
            'transcription': '',
            'segments': [],
            'word_segments': [],
            'success': False,
            'error': 'WhisperX is not installed. Please install it with: pip install whisperx'
        }
    
    try:
        if not os.path.exists(audio_path):
            return {
                'transcription': '',
                'segments': [],
                'word_segments': [],
                'success': False,
                'error': f'File not found: {audio_path}'
            }
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        batch_size = 8 if device == "cuda" else 4  # batch size ì¤„ì„
        compute_type = "float16" if device == "cuda" else "int8"
        
        print(f"[WhisperX] Starting transcription and alignment for: {audio_path}")
        start_time = time.time()
        
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = whisperx.load_audio(audio_path)
        
        # 2. WhisperX ëª¨ë¸ ë¡œë“œ
        whisperx_model, model_a, metadata = get_whisperx_model()
        if whisperx_model is None:
            return {
                'transcription': '',
                'segments': [],
                'word_segments': [],
                'success': False,
                'error': 'Failed to load WhisperX models'
            }
        
        # 3. ì „ì‚¬ ìˆ˜í–‰ (í•œêµ­ì–´ë¡œ ê³ ì •)
        result = whisperx_model.transcribe(audio, batch_size=batch_size, language="ko")
        
        # ì „ì‚¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        transcription = ""
        if 'segments' in result:
            transcription = " ".join([seg['text'] for seg in result['segments']])
        
        # 4. Forced alignment ìˆ˜í–‰
        result = whisperx.align(result["segments"], model_a, metadata, audio, device, return_char_alignments=False)
        
        # 5. ê²°ê³¼ ì •ë¦¬
        segments = []
        word_segments = []
        
        if 'segments' in result:
            for segment in result['segments']:
                seg_data = {
                    'start': segment.get('start', 0),
                    'end': segment.get('end', 0),
                    'text': segment.get('text', ''),
                    'id': segment.get('id', 0)
                }
                segments.append(seg_data)
                
                # ë‹¨ì–´ ë ˆë²¨ alignment
                if 'words' in segment:
                    for word in segment['words']:
                        word_data = {
                            'start': word.get('start', 0),
                            'end': word.get('end', 0),
                            'word': word.get('word', ''),
                            'score': word.get('score', 0.0),
                            'segment_id': segment.get('id', 0)
                        }
                        word_segments.append(word_data)
        
        elapsed = time.time() - start_time
        print(f"[WhisperX] Completed in {elapsed:.2f} seconds")
        
        return {
            'transcription': transcription.strip(),
            'segments': segments,
            'word_segments': word_segments,
            'success': True,
            'error': None
        }
        
    except Exception as e:
        print(f"[WhisperX Error] Failed to process {audio_path}: {e}")
        return {
            'transcription': '',
            'segments': [],
            'word_segments': [],
            'success': False,
            'error': str(e)
        }
    finally:
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()


def format_alignment_for_frontend(alignment_data):
    """
    alignment ë°ì´í„°ë¥¼ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
    
    Args:
        alignment_data (dict): WhisperX alignment ê²°ê³¼
        
    Returns:
        dict: í”„ë¡ íŠ¸ì—”ë“œìš© í¬ë§·ëœ ë°ì´í„°
    """
    if not alignment_data or not alignment_data.get('success'):
        return {
            'segments': [],
            'words': [],
            'transcription': '',
            'duration': 0
        }
    
    segments = alignment_data.get('segments', [])
    words = alignment_data.get('word_segments', [])
    
    # ì „ì²´ ê¸¸ì´ ê³„ì‚°
    duration = 0
    if segments:
        duration = max([seg.get('end', 0) for seg in segments])
    elif words:
        duration = max([word.get('end', 0) for word in words])
    
    return {
        'segments': segments,
        'words': words,
        'transcription': alignment_data.get('transcription', ''),
        'duration': duration
    }

