"""
Speaker Diarization Utilities using Pyannote
í™”ì ë¶„ë¦¬(Speaker Diarization) ê¸°ëŠ¥ êµ¬í˜„
"""

import os
import torch
from pyannote.audio import Pipeline
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class SpeakerDiarizer:
    """
    Pyannote.audioë¥¼ ì‚¬ìš©í•œ í™”ì ë¶„ë¦¬(Speaker Diarization) í´ë˜ìŠ¤
    
    ì•„ë™ ìŒì„± ë°ì´í„°ì—ì„œ ì„ ìƒë‹˜ê³¼ ì•„ë™ì˜ ë°œí™”ë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, use_auth_token: Optional[str] = None):
        """
        Args:
            use_auth_token: Hugging Face ì¸ì¦ í† í° (pyannote ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”)
        """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.pipeline = None
        self.use_auth_token = use_auth_token or os.environ.get('HUGGINGFACE_TOKEN')
        
        logger.info(f"ğŸ™ï¸ SpeakerDiarizer ì´ˆê¸°í™” (device: {self.device})")
    
    def load_pipeline(self):
        """Pyannote diarization íŒŒì´í”„ë¼ì¸ ë¡œë“œ"""
        if self.pipeline is not None:
            return
        
        try:
            logger.info("ğŸ“¥ Pyannote diarization íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘...")
            
            # Pyannote 3.x ë²„ì „ ì‚¬ìš©
            self.pipeline = Pipeline.from_pretrained(
                "pyannote/speaker-diarization-3.1",
                use_auth_token=self.use_auth_token
            )
            
            # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì´ë™
            if torch.cuda.is_available():
                self.pipeline.to(self.device)
            
            logger.info("âœ… Pyannote íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ Pyannote íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def perform_diarization(
        self, 
        audio_path: str, 
        num_speakers: Optional[int] = None,
        min_speakers: int = 1,
        max_speakers: int = 2
    ) -> Dict:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì— ëŒ€í•´ í™”ì ë¶„ë¦¬ ìˆ˜í–‰
        
        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            num_speakers: ì˜ˆìƒ í™”ì ìˆ˜ (Noneì´ë©´ ìë™ ê°ì§€)
            min_speakers: ìµœì†Œ í™”ì ìˆ˜
            max_speakers: ìµœëŒ€ í™”ì ìˆ˜
        
        Returns:
            Dict: {
                'segments': [{'start': float, 'end': float, 'speaker': str}, ...],
                'num_speakers': int,
                'status': str
            }
        """
        self.load_pipeline()
        
        try:
            logger.info(f"ğŸ¤ í™”ì ë¶„ë¦¬ ì‹œì‘: {audio_path}")
            
            # Diarization ì‹¤í–‰
            if num_speakers is not None:
                diarization = self.pipeline(
                    audio_path,
                    num_speakers=num_speakers
                )
            else:
                diarization = self.pipeline(
                    audio_path,
                    min_speakers=min_speakers,
                    max_speakers=max_speakers
                )
            
            # ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            segments = []
            speakers = set()
            
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                segments.append({
                    'start': float(turn.start),
                    'end': float(turn.end),
                    'duration': float(turn.end - turn.start),
                    'speaker': speaker
                })
                speakers.add(speaker)
            
            # í™”ìë³„ë¡œ ì •ë ¬ ë° í†µê³„
            segments_sorted = sorted(segments, key=lambda x: x['start'])
            
            # í™”ìë³„ ì´ ë°œí™” ì‹œê°„ ê³„ì‚°
            speaker_stats = {}
            for speaker in speakers:
                speaker_segments = [s for s in segments if s['speaker'] == speaker]
                total_duration = sum(s['duration'] for s in speaker_segments)
                speaker_stats[speaker] = {
                    'total_duration': total_duration,
                    'num_segments': len(speaker_segments),
                    'percentage': 0.0  # ë‚˜ì¤‘ì— ê³„ì‚°
                }
            
            # ì „ì²´ ë°œí™” ì‹œê°„ ëŒ€ë¹„ ë¹„ìœ¨ ê³„ì‚°
            total_speech_time = sum(s['duration'] for s in segments)
            for speaker in speaker_stats:
                speaker_stats[speaker]['percentage'] = (
                    speaker_stats[speaker]['total_duration'] / total_speech_time * 100
                    if total_speech_time > 0 else 0.0
                )
            
            result = {
                'segments': segments_sorted,
                'num_speakers': len(speakers),
                'speakers': list(speakers),
                'speaker_stats': speaker_stats,
                'total_speech_time': total_speech_time,
                'status': 'completed'
            }
            
            logger.info(f"âœ… í™”ì ë¶„ë¦¬ ì™„ë£Œ: {len(speakers)}ëª…ì˜ í™”ì ê°ì§€, {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
            return result
            
        except Exception as e:
            logger.error(f"âŒ í™”ì ë¶„ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'segments': [],
                'num_speakers': 0,
                'speakers': [],
                'speaker_stats': {},
                'total_speech_time': 0.0,
                'status': 'failed',
                'error': str(e)
            }
    
    def assign_speaker_labels(
        self,
        diarization_result: Dict,
        label_map: Optional[Dict[str, str]] = None
    ) -> Dict:
        """
        í™”ì ë ˆì´ë¸”ì„ ì˜ë¯¸ìˆëŠ” ì´ë¦„ìœ¼ë¡œ ë³€ê²½
        
        Args:
            diarization_result: perform_diarization ê²°ê³¼
            label_map: í™”ì ë ˆì´ë¸” ë§¤í•‘ (ì˜ˆ: {'SPEAKER_00': 'ì•„ë™', 'SPEAKER_01': 'ì„ ìƒë‹˜'})
        
        Returns:
            ë ˆì´ë¸”ì´ ë³€ê²½ëœ diarization ê²°ê³¼
        """
        if label_map is None:
            # ê¸°ë³¸ ë§¤í•‘: ë°œí™”ëŸ‰ì´ ë§ì€ ìˆœì„œëŒ€ë¡œ ì•„ë™, ì„ ìƒë‹˜ìœ¼ë¡œ ì¶”ì •
            speaker_stats = diarization_result.get('speaker_stats', {})
            sorted_speakers = sorted(
                speaker_stats.items(),
                key=lambda x: x[1]['total_duration'],
                reverse=True
            )
            
            label_map = {}
            labels = ['ì•„ë™', 'ì„ ìƒë‹˜', 'í™”ì3', 'í™”ì4']
            for idx, (speaker, _) in enumerate(sorted_speakers):
                if idx < len(labels):
                    label_map[speaker] = labels[idx]
                else:
                    label_map[speaker] = f'í™”ì{idx + 1}'
        
        # ì„¸ê·¸ë¨¼íŠ¸ì˜ í™”ì ë ˆì´ë¸” ë³€ê²½
        new_segments = []
        for segment in diarization_result['segments']:
            new_segment = segment.copy()
            original_speaker = segment['speaker']
            new_segment['speaker'] = label_map.get(original_speaker, original_speaker)
            new_segment['original_speaker'] = original_speaker
            new_segments.append(new_segment)
        
        # speaker_statsì˜ í‚¤ë„ ë³€ê²½
        new_speaker_stats = {}
        for original_speaker, stats in diarization_result['speaker_stats'].items():
            new_label = label_map.get(original_speaker, original_speaker)
            new_stats = stats.copy()
            new_stats['original_label'] = original_speaker
            new_speaker_stats[new_label] = new_stats
        
        # ìƒˆë¡œìš´ í™”ì ë¦¬ìŠ¤íŠ¸
        new_speakers = [label_map.get(s, s) for s in diarization_result['speakers']]
        
        return {
            **diarization_result,
            'segments': new_segments,
            'speakers': new_speakers,
            'speaker_stats': new_speaker_stats,
            'label_map': label_map
        }
    
    def extract_speaker_audio(
        self,
        audio_path: str,
        diarization_result: Dict,
        speaker: str,
        output_path: str
    ) -> bool:
        """
        íŠ¹ì • í™”ìì˜ ë°œí™”ë§Œ ì¶”ì¶œí•˜ì—¬ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            audio_path: ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            diarization_result: perform_diarization ê²°ê³¼
            speaker: ì¶”ì¶œí•  í™”ì ë ˆì´ë¸”
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            from pydub import AudioSegment
            
            # ì›ë³¸ ì˜¤ë””ì˜¤ ë¡œë“œ
            audio = AudioSegment.from_wav(audio_path)
            
            # í•´ë‹¹ í™”ìì˜ ì„¸ê·¸ë¨¼íŠ¸ë§Œ ì¶”ì¶œ
            speaker_segments = [
                s for s in diarization_result['segments']
                if s['speaker'] == speaker or s.get('original_speaker') == speaker
            ]
            
            if not speaker_segments:
                logger.warning(f"âš ï¸ í™”ì '{speaker}'ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
            combined_audio = AudioSegment.empty()
            for segment in speaker_segments:
                start_ms = int(segment['start'] * 1000)
                end_ms = int(segment['end'] * 1000)
                combined_audio += audio[start_ms:end_ms]
            
            # íŒŒì¼ ì €ì¥
            combined_audio.export(output_path, format="wav")
            logger.info(f"âœ… í™”ì '{speaker}' ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ í™”ì ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return False


def format_diarization_for_frontend(diarization_data: Dict) -> Dict:
    """
    Diarization ê²°ê³¼ë¥¼ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í‘œì‹œí•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ë³€í™˜
    
    Args:
        diarization_data: perform_diarization ë˜ëŠ” assign_speaker_labels ê²°ê³¼
    
    Returns:
        í”„ë¡ íŠ¸ì—”ë“œìš©ìœ¼ë¡œ í¬ë§·ëœ ë°ì´í„°
    """
    if not diarization_data or diarization_data.get('status') != 'completed':
        return {}
    
    # ì‹œê°„ í¬ë§·íŒ… í•¨ìˆ˜
    def format_time(seconds):
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes:02d}:{secs:05.2f}"
    
    # ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í™”ìë³„ë¡œ ê·¸ë£¹í™”
    segments_by_speaker = {}
    for segment in diarization_data['segments']:
        speaker = segment['speaker']
        if speaker not in segments_by_speaker:
            segments_by_speaker[speaker] = []
        
        segments_by_speaker[speaker].append({
            'start': segment['start'],
            'end': segment['end'],
            'start_formatted': format_time(segment['start']),
            'end_formatted': format_time(segment['end']),
            'duration': segment['duration'],
            'duration_formatted': f"{segment['duration']:.2f}ì´ˆ"
        })
    
    # íƒ€ì„ë¼ì¸ í˜•íƒœë¡œë„ ì œê³µ (WaveSurfer.js regions ë“±ì— í™œìš©)
    timeline = []
    for segment in diarization_data['segments']:
        timeline.append({
            'start': segment['start'],
            'end': segment['end'],
            'speaker': segment['speaker'],
            'label': f"{segment['speaker']} ({format_time(segment['start'])} - {format_time(segment['end'])})"
        })
    
    return {
        'num_speakers': diarization_data['num_speakers'],
        'speakers': diarization_data['speakers'],
        'speaker_stats': diarization_data['speaker_stats'],
        'segments_by_speaker': segments_by_speaker,
        'timeline': timeline,
        'total_speech_time': diarization_data['total_speech_time'],
        'total_speech_time_formatted': format_time(diarization_data['total_speech_time'])
    }
